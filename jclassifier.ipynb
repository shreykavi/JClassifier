{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport random\nimport gc\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n%matplotlib inline\nnum_to_test = 11\n\ndef process_imgs(imgs): #read and resize all images w/ cv2\n    # 150 x 150 RGB\n    nrows = 150\n    ncolumns = 150\n    channels = 3\n\n    x = []\n    for img in imgs:\n        try:\n            y = cv2.resize(cv2.imread(img, cv2.IMREAD_COLOR), (nrows, ncolumns), interpolation=cv2.INTER_CUBIC)/255\n            x.append(y)\n        except Exception as e:\n#             print(str(e))\n            pass\n    return x\n\n# Import and setup data\nall_data = []\nall_labels = []\nfor x in range(1,(num_to_test+1)):\n    data = ['/kaggle/input/{}/{}/{}'.format(x,x,i) for i in os.listdir('/kaggle/input/{}/{}'.format(x,x))]\n    data = process_imgs(data)\n    all_data.extend(data) #append contents of data  \n    all_labels = np.append(all_labels, [x-1 for i in range(len(data))]) #append x len(data) times\n    del data\n\nall_data = np.asarray(all_data)\n    \n# here X is for data, y is for labels \nprint(all_data.shape)\nprint(all_labels.shape)\n\nfrom keras.utils import to_categorical\n\nX_train, X_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.25)\n\ny_train = to_categorical(y_train, num_classes=num_to_test)\ny_test = to_categorical(y_test, num_classes=num_to_test)\n\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)\n\nprint(\"> DONE SETUP\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## This is our original CNN\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\n\ncnn = Sequential()\n# cnn.add(conv_base)\ncnn.add(Conv2D(filters=4, kernel_size=(3, 3), padding='same', activation='relu', input_shape=X_train.shape[1:]))\n\ncnn.add(MaxPool2D(pool_size=(2, 2)))\ncnn.add(Conv2D(16, kernel_size=(3, 3), padding='same', activation='relu'))\ncnn.add(MaxPool2D(pool_size=(2, 2)))\ncnn.add(Flatten())\ncnn.add(Dense(32, activation='relu'))\n\ncnn.add(Dense(num_to_test, activation='softmax'))\n\ncnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ndatagen = ImageDataGenerator(\n        featurewise_center=True, # set input mean to 0 over the dataset\n        samplewise_center=False, # set each sample mean to 0\n        featurewise_std_normalization=True, # divide inputs by std of the dataset\n        samplewise_std_normalization=False, # divide each input by its std\n        zca_whitening=False, # apply ZCA whitening\n        rotation_range=20, # randomly rotate images in the range (degrees, 0 to 180)\n#         width_shift_range=0.2, # randomly shift images horizontally (fraction of total width)\n#         height_shift_range=0.2, # randomly shift images vertically (fraction of total height)\n#         horizontal_flip=True, # randomly flip images\n#         vertical_flip=False # randomly flip images\n)\n\ndatagen.fit(X_train[0:100]) # let's say X_sample is a small-ish but statistically representative sample of your data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## This is using transfer learning\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications import InceptionResNetV2\n\nconv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(150,150,3))\n\ncnn = Sequential()\ncnn.add(conv_base)\ncnn.add(Conv2D(filters=4, kernel_size=(3, 3), padding='same', activation='relu', input_shape=X_train.shape[1:]))\ncnn.add(Flatten())\ncnn.add(Dense(32, activation='relu'))\n\ncnn.add(Dense(num_to_test, activation='softmax'))\n\ncnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\ndatagen = ImageDataGenerator(\n        featurewise_center=True, # set input mean to 0 over the dataset\n        samplewise_center=False, # set each sample mean to 0\n        featurewise_std_normalization=True, # divide inputs by std of the dataset\n        samplewise_std_normalization=False, # divide each input by its std\n        zca_whitening=False, # apply ZCA whitening\n        rotation_range=20, # randomly rotate images in the range (degrees, 0 to 180)\n#         width_shift_range=0.2, # randomly shift images horizontally (fraction of total width)\n#         height_shift_range=0.2, # randomly shift images vertically (fraction of total height)\n#         horizontal_flip=True, # randomly flip images\n#         vertical_flip=False # randomly flip images\n)\n\ndatagen.fit(X_train[0:100]) # let's say X_sample is a small-ish but statistically representative sample of your data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This section is where the model is fit to the data\n\nBS=32\nloss = cnn.fit(X_train, \n    y_train, \n    batch_size=128,\n    epochs=50)\nevals = cnn.evaluate(X_test, y_test, verbose=1)\nprint('B4 AUG:\\ntest loss: {}, test accuracy: {}'.format(evals[0], evals[1]))\n\ncnn.fit_generator(datagen.flow(X_train, y_train, batch_size=BS),\n    validation_data=(X_test, y_test), \n    steps_per_epoch=len(X_train) // BS,\n    epochs=25)\n\nevals = cnn.evaluate(X_test, y_test, verbose=1)\nprint('test loss: {}, test accuracy: {}'.format(evals[0], evals[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir(loss.history)\nloss.history.keys()\nplt.plot(loss.history['accuracy'])\n# plt.plot(loss.history['val_accuracy'])\nplt.title('Convolutional Neural Network')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cleanup\ndel all_data\ngc.collect()\nprint(\"DONE CLEANUP\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}